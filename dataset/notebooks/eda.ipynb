{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASAP Dataset\n",
    "\n",
    "The ASAP dataset contains essays from 8 different prompts with human-scored ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12976, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asap_path = BASE_DIR / \"asap-aes\" / \"training_set_rel3.tsv\"\n",
    "asap_df = pd.read_csv(asap_path, sep=\"\\t\", encoding=\"latin-1\")\n",
    "\n",
    "print(f\"Shape: {asap_df.shape}\")\n",
    "asap_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1', 'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2', 'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3', 'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1', 'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5', 'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3', 'rater3_trait4', 'rater3_trait5', 'rater3_trait6']\n",
      "\n",
      "Essay set distribution:\n",
      "essay_set\n",
      "1    1783\n",
      "2    1800\n",
      "3    1726\n",
      "4    1770\n",
      "5    1805\n",
      "6    1800\n",
      "7    1569\n",
      "8     723\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "rater3_domain1    12848\n",
      "rater1_domain2    11176\n",
      "rater2_domain2    11176\n",
      "domain2_score     11176\n",
      "rater1_trait1     10684\n",
      "rater1_trait2     10684\n",
      "rater1_trait3     10684\n",
      "rater1_trait4     10684\n",
      "rater1_trait5     12253\n",
      "rater1_trait6     12253\n",
      "rater2_trait1     10684\n",
      "rater2_trait2     10684\n",
      "rater2_trait3     10684\n",
      "rater2_trait4     10684\n",
      "rater2_trait5     12253\n",
      "rater2_trait6     12253\n",
      "rater3_trait1     12848\n",
      "rater3_trait2     12848\n",
      "rater3_trait3     12848\n",
      "rater3_trait4     12848\n",
      "rater3_trait5     12848\n",
      "rater3_trait6     12848\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\")\n",
    "print(asap_df.columns.tolist())\n",
    "print(f\"\\nEssay set distribution:\")\n",
    "print(asap_df[\"essay_set\"].value_counts().sort_index())\n",
    "print(f\"\\nMissing values:\")\n",
    "print(asap_df.isnull().sum()[asap_df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay length statistics (word count):\n",
      "            count   mean    std   min    25%    50%    75%     max\n",
      "essay_set                                                         \n",
      "1          1783.0  365.7  119.6   8.0  286.5  365.0  441.0   785.0\n",
      "2          1800.0  380.7  156.2  31.0  278.8  368.0  470.2  1064.0\n",
      "3          1726.0  108.7   53.3  10.0   67.0  100.5  146.0   375.0\n",
      "4          1770.0   94.5   51.9   2.0   54.0   87.0  127.0   357.0\n",
      "5          1805.0  122.1   57.3   4.0   80.0  119.0  158.0   416.0\n",
      "6          1800.0  153.3   55.8   3.0  117.0  153.0  188.0   454.0\n",
      "7          1569.0  168.2   85.3   5.0  105.0  154.0  215.0   592.0\n",
      "8           723.0  604.9  202.0   4.0  465.5  626.0  790.0   856.0\n",
      "\n",
      "Sample essay (set 1):\n",
      "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n"
     ]
    }
   ],
   "source": [
    "asap_df[\"word_count\"] = asap_df[\"essay\"].str.split().str.len()\n",
    "\n",
    "print(\"Essay length statistics (word count):\")\n",
    "print(asap_df.groupby(\"essay_set\")[\"word_count\"].describe().round(1))\n",
    "print(f\"\\nSample essay (set 1):\")\n",
    "print(asap_df.loc[0, \"essay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASAP++ Dataset\n",
    "\n",
    "The ASAP++ dataset provides trait-level scores for essays from prompts 1-6. Different prompts use different scoring criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: 1783 rows\n",
      "Prompt 2: 1800 rows\n",
      "Prompt 3: 1726 rows\n",
      "Prompt 4: 1772 rows\n",
      "Prompt 5: 1805 rows\n",
      "Prompt 6: 1800 rows\n"
     ]
    }
   ],
   "source": [
    "asap_pp_dir = BASE_DIR / \"asap++\"\n",
    "asap_pp_dfs = {}\n",
    "\n",
    "for i in range(1, 7):\n",
    "    path = asap_pp_dir / f\"Prompt-{i}.csv\"\n",
    "    asap_pp_dfs[i] = pd.read_csv(path)\n",
    "    print(f\"Prompt {i}: {len(asap_pp_dfs[i])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts 1-2 columns (Rubric 1):\n",
      "['EssayID', 'Content', 'Organization', 'Word Choice', 'Sentence Fluency', 'Conventions']\n",
      "\n",
      "Prompts 3-6 columns (Rubric 2):\n",
      "['Essay ID', 'Content', 'Prompt Adherence', 'Language', 'Narrativity']\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompts 1-2 columns (Rubric 1):\")\n",
    "print(asap_pp_dfs[1].columns.tolist())\n",
    "print(\"\\nPrompts 3-6 columns (Rubric 2):\")\n",
    "print(asap_pp_dfs[3].columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score distributions for Prompt 1 (Rubric 1):\n",
      "\n",
      "Content:\n",
      "Content\n",
      "1     23\n",
      "2     91\n",
      "3    543\n",
      "4    684\n",
      "5    363\n",
      "6     79\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Organization:\n",
      "Organization\n",
      "1     28\n",
      "2    102\n",
      "3    586\n",
      "4    702\n",
      "5    324\n",
      "6     41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Word Choice:\n",
      "Word Choice\n",
      "1     25\n",
      "2    110\n",
      "3    674\n",
      "4    633\n",
      "5    285\n",
      "6     56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentence Fluency:\n",
      "Sentence Fluency\n",
      "1     27\n",
      "2    104\n",
      "3    578\n",
      "4    676\n",
      "5    352\n",
      "6     46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conventions:\n",
      "Conventions\n",
      "1     27\n",
      "2    109\n",
      "3    574\n",
      "4    702\n",
      "5    337\n",
      "6     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Score distributions for Prompt 3 (Rubric 2):\n",
      "\n",
      "Content:\n",
      "Content\n",
      "0    258\n",
      "1    597\n",
      "2    734\n",
      "3    137\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Prompt Adherence:\n",
      "Prompt Adherence\n",
      "0    263\n",
      "1    558\n",
      "2    721\n",
      "3    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Language:\n",
      "Language\n",
      "0    233\n",
      "1    615\n",
      "2    708\n",
      "3    170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Narrativity:\n",
      "Narrativity\n",
      "0    268\n",
      "1    637\n",
      "2    613\n",
      "3    208\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Score distributions for Prompt 1 (Rubric 1):\")\n",
    "for col in [\"Content\", \"Organization\", \"Word Choice\", \"Sentence Fluency\", \"Conventions\"]:\n",
    "    if col in asap_pp_dfs[1].columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(asap_pp_dfs[1][col].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nScore distributions for Prompt 3 (Rubric 2):\")\n",
    "for col in [\"Content\", \"Prompt Adherence\", \"Language\", \"Narrativity\"]:\n",
    "    if col in asap_pp_dfs[3].columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(asap_pp_dfs[3][col].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASAP essays (sets 1-6): 10684\n",
      "ASAP++ essays: 10685\n",
      "Overlapping IDs: 10683\n",
      "Match rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "asap_sets_1_6 = asap_df[asap_df[\"essay_set\"] <= 6]\n",
    "asap_ids = set(asap_sets_1_6[\"essay_id\"])\n",
    "\n",
    "asap_pp_ids = set()\n",
    "for prompt_num, df in asap_pp_dfs.items():\n",
    "    id_col = \"EssayID\" if \"EssayID\" in df.columns else \"Essay ID\"\n",
    "    asap_pp_ids.update(df[id_col].tolist())\n",
    "\n",
    "overlap = asap_ids & asap_pp_ids\n",
    "\n",
    "print(f\"ASAP essays (sets 1-6): {len(asap_ids)}\")\n",
    "print(f\"ASAP++ essays: {len(asap_pp_ids)}\")\n",
    "print(f\"Overlapping IDs: {len(overlap)}\")\n",
    "print(f\"Match rate: {len(overlap) / len(asap_ids) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rubric 1 (Prompts 1-2) criteria:\n",
      "* Content (id=1): scores 1-6\n",
      "* Organization (id=2): scores 1-6\n",
      "* Word Choice (id=3): scores 1-6\n",
      "* Sentence Fluency (id=4): scores 1-6\n",
      "* Conventions (id=5): scores 1-6\n",
      "\n",
      "Rubric 2 (Prompts 3-6) criteria:\n",
      "* Content (id=1): scores 0-3\n",
      "* Prompt Adherence (id=2): scores 0-3\n",
      "* Language (id=3): scores 0-3\n",
      "* Narrativity (id=4): scores 0-3\n"
     ]
    }
   ],
   "source": [
    "rubric_1_path = BASE_DIR / \"training\" / \"rubrics\" / \"1.json\"\n",
    "rubric_2_path = BASE_DIR / \"training\" / \"rubrics\" / \"2.json\"\n",
    "\n",
    "with open(rubric_1_path) as f:\n",
    "    rubric_1 = json.load(f)\n",
    "with open(rubric_2_path) as f:\n",
    "    rubric_2 = json.load(f)\n",
    "\n",
    "print(\"Rubric 1 (Prompts 1-2) criteria:\")\n",
    "for c in rubric_1[\"criteria\"]:\n",
    "    levels = [l[\"score\"] for l in c[\"levels\"]]\n",
    "    print(f\"* {c['name']} (id={c['id']}): scores {min(levels)}-{max(levels)}\")\n",
    "\n",
    "print(\"\\nRubric 2 (Prompts 3-6) criteria:\")\n",
    "for c in rubric_2[\"criteria\"]:\n",
    "    levels = [l[\"score\"] for l in c[\"levels\"]]\n",
    "    print(f\"* {c['name']} (id={c['id']}): scores {min(levels)}-{max(levels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 3 essays\n",
      "\n",
      "Schema: id, prompt_id, rubric_id, essay, scores\n",
      "* scores: [{criteria_id, level_id}, ...]\n",
      "\n",
      "Example essay (id=1):\n",
      "* prompt_id: 1\n",
      "* rubric_id: 1\n",
      "* essay: Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n",
      "* scores: [{'criteria_id': 1, 'level_id': 4}, {'criteria_id': 2, 'level_id': 3}, {'criteria_id': 3, 'level_id': 3}, {'criteria_id': 4, 'level_id': 3}, {'criteria_id': 5, 'level_id': 3}]\n"
     ]
    }
   ],
   "source": [
    "sample_path = BASE_DIR / \"training\" / \"sample.json\"\n",
    "with open(sample_path) as f:\n",
    "    sample = json.load(f)\n",
    "\n",
    "print(f\"Sample contains {len(sample)} essays\\n\")\n",
    "print(\"Schema: id, prompt_id, rubric_id, essay, scores\")\n",
    "print(\"* scores: [{criteria_id, level_id}, ...]\\n\")\n",
    "\n",
    "example = sample[0]\n",
    "print(f\"Example essay (id={example['id']}):\")\n",
    "print(f\"* prompt_id: {example['prompt_id']}\")\n",
    "print(f\"* rubric_id: {example['rubric_id']}\")\n",
    "print(f\"* essay: {example['essay']}\")\n",
    "print(f\"* scores: {example['scores']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total merged essays: 10683\n",
      "\n",
      "Distribution by prompt_id:\n",
      "prompt_id\n",
      "1    1783\n",
      "2    1799\n",
      "3    1726\n",
      "4    1770\n",
      "5    1805\n",
      "6    1800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution by rubric_id:\n",
      "rubric_id\n",
      "1    3582\n",
      "2    7101\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "essays_path = BASE_DIR / \"training\" / \"essays.json\"\n",
    "with open(essays_path) as f:\n",
    "    essays = json.load(f)\n",
    "\n",
    "essays_df = pd.DataFrame(essays)\n",
    "\n",
    "print(f\"Total merged essays: {len(essays_df)}\")\n",
    "print(f\"\\nDistribution by prompt_id:\")\n",
    "print(essays_df[\"prompt_id\"].value_counts().sort_index())\n",
    "print(f\"\\nDistribution by rubric_id:\")\n",
    "print(essays_df[\"rubric_id\"].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
